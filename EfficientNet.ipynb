{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.10 64-bit ('tengpu': conda)"
    },
    "interpreter": {
      "hash": "be9da68a2e5ae60033c8673d7ecd6236339231adc2ba567b761567d167edd1e5"
    },
    "colab": {
      "name": "Efficientnet-NextLab-MODELV2 copy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 다운로드"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#!pip install -U git+https://github.com/leondgarse/keras_efficientnet_v2"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPU 버전 체크"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "source": [
        "!nvidia-smi"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Sep  9 20:10:09 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 471.11       Driver Version: 471.11       CUDA Version: 11.4     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
            "|  0%   43C    P8    21W / 250W |  11089MiB / 11264MiB |     15%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      1540    C+G   ...b3d8bbwe\\WinStore.App.exe    N/A      |\n",
            "|    0   N/A  N/A      4728    C+G   ...ekyb3d8bbwe\\HxOutlook.exe    N/A      |\n",
            "|    0   N/A  N/A     10096    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
            "|    0   N/A  N/A     10356    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
            "|    0   N/A  N/A     10580    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
            "|    0   N/A  N/A     10672    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     11148    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
            "|    0   N/A  N/A     13172    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
            "|    0   N/A  N/A     13304    C+G   ...ata\\cef_x86\\zCefAgent.exe    N/A      |\n",
            "|    0   N/A  N/A     13412    C+G   ...kyb3d8bbwe\\Calculator.exe    N/A      |\n",
            "|    0   N/A  N/A     14820    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
            "|    0   N/A  N/A     15200    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n",
            "|    0   N/A  N/A     15744    C+G   ...wekyb3d8bbwe\\Music.UI.exe    N/A      |\n",
            "|    0   N/A  N/A     16060    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
            "|    0   N/A  N/A     20436    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     20540    C+G   ...TeamViewer\\TeamViewer.exe    N/A      |\n",
            "|    0   N/A  N/A     21732    C+G   ...\\app-1.0.9002\\Discord.exe    N/A      |\n",
            "|    0   N/A  N/A     22252      C   ...a3\\envs\\tengpu\\python.exe    N/A      |\n",
            "|    0   N/A  N/A     22484    C+G   Insufficient Permissions        N/A      |\n",
            "|    0   N/A  N/A     23548    C+G   ...Roaming\\Zoom\\bin\\Zoom.exe    N/A      |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lm-RZdzg-kZ0",
        "outputId": "1d317ded-56ff-4dfe-9971-30add89ec754"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모듈 Import"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "source": [
        "import tensorflow as tf\r\n",
        "import pandas as pd\r\n",
        "import random\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "import keras_efficientnet_v2 as efficientnet_v2\r\n",
        "\r\n",
        "from tensorflow.keras.layers import Dense, Input, Conv2D, Dropout, Flatten, Activation, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\r\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\r\n",
        "from tensorflow.keras.models import Model, Sequential\r\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from tensorflow.keras.preprocessing import image\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow import keras\r\n",
        "from skimage.transform import resize\r\n",
        "from PIL import Image\r\n",
        "import cv2\r\n",
        "import numpy as np\r\n",
        "import glob\r\n",
        "from tqdm import tqdm"
      ],
      "outputs": [],
      "metadata": {
        "id": "d4xfPyC1jEu7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration"
      ],
      "metadata": {
        "id": "CoJcxKFC-kZ5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "source": [
        "seed = 42\r\n",
        "batch_size = 64\r\n",
        "width = 240\r\n",
        "height = 240\r\n",
        "epochs = 30\r\n",
        "NUM_TRAIN = 0\r\n",
        "NUM_TEST = 0\r\n",
        "dropout_rate = 0.2\r\n",
        "input_shape = (height, width, 3)\r\n",
        "num_classes = 322"
      ],
      "outputs": [],
      "metadata": {
        "id": "_s1Datma-kZ6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "source": [
        "print(tf.__version__)\r\n",
        "tf.random.set_seed(seed)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPh0m3Za-kZ6",
        "outputId": "7cf43678-f642-4027-89a4-de40c2664a73"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read DataFrame\n",
        "미리 저장된 데이터 프레임을 읽어옵니다."
      ],
      "metadata": {
        "id": "25-GQkcC-kZ7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "source": [
        "df = pd.read_json('./data/dataset/car.json', \"r\", encoding='UTF8')\r\n",
        "df = df.T.rename_axis('class_name').reset_index()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-4bb5d48c4a0b>:1: FutureWarning: Starting with Pandas version 2.0 all arguments of read_json except for the argument 'path_or_buf' will be keyword-only\n",
            "  df = pd.read_json('./data/dataset/car.json', \"r\", encoding='UTF8')\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "cPBaza87-kZ7",
        "outputId": "e30f5b84-c147-4adb-ef8c-d48ba8ccd1b0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataFrame Split"
      ],
      "metadata": {
        "id": "tvEJ74Qx-kZ8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "source": [
        "def train_test_split_custom(df, train_size, random_state=42):\r\n",
        "    train_size = 0.8\r\n",
        "\r\n",
        "    df_train = pd.DataFrame(data={'class_name':[]})\r\n",
        "    df_test = pd.DataFrame(data={'class_name':[]})\r\n",
        "\r\n",
        "    count_train = 0\r\n",
        "    count_test = 0\r\n",
        "    for index, class_name in enumerate(df['class_name']) : \r\n",
        "        image_paths = df['image_path'].iloc[index]\r\n",
        "        random.Random(random_state).shuffle(image_paths)\r\n",
        "        image_paths_train = image_paths[: round(len(image_paths) * train_size)]\r\n",
        "        image_paths_test = image_paths[round(len(image_paths) * train_size):]\r\n",
        "\r\n",
        "        for path in image_paths_train :\r\n",
        "            df_train.loc[path] = df['class_name'].iloc[index]\r\n",
        "        for path in image_paths_test :\r\n",
        "            df_test.loc[path] = df['class_name'].iloc[index] \r\n",
        "\r\n",
        "    df_train = df_train.reset_index().rename(columns={\"index\": \"path\"})\r\n",
        "    df_test = df_test.reset_index().rename(columns={\"index\": \"path\"})\r\n",
        "    return df_train, df_test"
      ],
      "outputs": [],
      "metadata": {
        "id": "tHDr74bI-kZ8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "source": [
        "df_train , df_valid = train_test_split_custom(df, train_size=0.8, random_state=seed)"
      ],
      "outputs": [],
      "metadata": {
        "id": "_Hr76M1A-kZ8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "source": [
        "df_train.tail()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>class_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25755</th>\n",
              "      <td>./data/dataset/혼다_세단_어코드_2018-2020/세단_어코드-212_...</td>\n",
              "      <td>혼다/세단_어코드/2018-2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25756</th>\n",
              "      <td>./data/dataset/혼다_세단_어코드_2018-2020/세단_어코드-212.jpg</td>\n",
              "      <td>혼다/세단_어코드/2018-2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25757</th>\n",
              "      <td>./data/dataset/혼다_세단_어코드_2018-2020/세단_어코드-130_...</td>\n",
              "      <td>혼다/세단_어코드/2018-2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25758</th>\n",
              "      <td>./data/dataset/혼다_세단_어코드_2018-2020/세단_어코드-184_...</td>\n",
              "      <td>혼다/세단_어코드/2018-2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25759</th>\n",
              "      <td>./data/dataset/혼다_세단_어코드_2018-2020/세단_어코드-154_...</td>\n",
              "      <td>혼다/세단_어코드/2018-2020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    path           class_name\n",
              "25755  ./data/dataset/혼다_세단_어코드_2018-2020/세단_어코드-212_...  혼다/세단_어코드/2018-2020\n",
              "25756  ./data/dataset/혼다_세단_어코드_2018-2020/세단_어코드-212.jpg  혼다/세단_어코드/2018-2020\n",
              "25757  ./data/dataset/혼다_세단_어코드_2018-2020/세단_어코드-130_...  혼다/세단_어코드/2018-2020\n",
              "25758  ./data/dataset/혼다_세단_어코드_2018-2020/세단_어코드-184_...  혼다/세단_어코드/2018-2020\n",
              "25759  ./data/dataset/혼다_세단_어코드_2018-2020/세단_어코드-154_...  혼다/세단_어코드/2018-2020"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "VHPHQnr3-kZ9",
        "outputId": "243ee436-2084-4f18-bf4b-ff9417ef74c8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "source": [
        "df_valid.tail()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>class_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6435</th>\n",
              "      <td>./data/dataset/혼다_세단_어코드_2018-2020/세단_어코드-239.jpg</td>\n",
              "      <td>혼다/세단_어코드/2018-2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6436</th>\n",
              "      <td>./data/dataset/혼다_세단_어코드_2018-2020/세단_어코드-226_...</td>\n",
              "      <td>혼다/세단_어코드/2018-2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6437</th>\n",
              "      <td>./data/dataset/혼다_세단_어코드_2018-2020/세단_어코드-115.jpg</td>\n",
              "      <td>혼다/세단_어코드/2018-2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6438</th>\n",
              "      <td>./data/dataset/혼다_세단_어코드_2018-2020/세단_어코드-16.jpg</td>\n",
              "      <td>혼다/세단_어코드/2018-2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6439</th>\n",
              "      <td>./data/dataset/혼다_세단_어코드_2018-2020/세단_어코드-177_...</td>\n",
              "      <td>혼다/세단_어코드/2018-2020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   path           class_name\n",
              "6435  ./data/dataset/혼다_세단_어코드_2018-2020/세단_어코드-239.jpg  혼다/세단_어코드/2018-2020\n",
              "6436  ./data/dataset/혼다_세단_어코드_2018-2020/세단_어코드-226_...  혼다/세단_어코드/2018-2020\n",
              "6437  ./data/dataset/혼다_세단_어코드_2018-2020/세단_어코드-115.jpg  혼다/세단_어코드/2018-2020\n",
              "6438   ./data/dataset/혼다_세단_어코드_2018-2020/세단_어코드-16.jpg  혼다/세단_어코드/2018-2020\n",
              "6439  ./data/dataset/혼다_세단_어코드_2018-2020/세단_어코드-177_...  혼다/세단_어코드/2018-2020"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "1aqLXzXu-kZ9",
        "outputId": "8a60397b-718b-460e-b0c4-ffc914ea7d12"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "source": [
        "NUM_TRAIN = len(df_train)\r\n",
        "NUM_TEST = len(df_valid)\r\n",
        "\r\n",
        "print(f'number of train : {NUM_TRAIN}\\nnumber of validation : {NUM_TEST}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of train : 25760\n",
            "number of validation : 6440\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV6dBInd-kZ9",
        "outputId": "b1ffadeb-2b01-4b16-c69e-5157751a1a8d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ImageDataGenerator"
      ],
      "metadata": {
        "id": "DKCYL3D7-kZ9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "source": [
        "train_datagen = ImageDataGenerator(\r\n",
        "      rescale=1./255,\r\n",
        "      rotation_range=40,\r\n",
        "      width_shift_range=0.2,\r\n",
        "      height_shift_range=0.2,\r\n",
        "      shear_range=0.2,\r\n",
        "      zoom_range=0.2,\r\n",
        "      horizontal_flip=True,\r\n",
        "      fill_mode='nearest')\r\n",
        "\r\n",
        "# Note that the validation data should not be augmented!\r\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\r\n",
        "\r\n",
        "train_generator = train_datagen.flow_from_dataframe(\r\n",
        "        df_train,\r\n",
        "        x_col = 'path',\r\n",
        "        y_col = 'class_name',\r\n",
        "        target_size=(height, width),\r\n",
        "        batch_size=batch_size,\r\n",
        "        class_mode='categorical')\r\n",
        "\r\n",
        "validation_generator = test_datagen.flow_from_dataframe(\r\n",
        "        df_valid,\r\n",
        "        x_col = 'path',\r\n",
        "        y_col = 'class_name',\r\n",
        "        target_size=(height, width),\r\n",
        "        batch_size=batch_size,\r\n",
        "        class_mode='categorical')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25760 validated image filenames belonging to 322 classes.\n",
            "Found 6440 validated image filenames belonging to 322 classes.\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8C4j0hx-kZ-",
        "outputId": "ee01ba1a-011b-408a-ba66-7a4e8ceebe90"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Create 함수"
      ],
      "metadata": {
        "id": "zUhAiRfXhsu9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "source": [
        "def create_model(version = 'v1', model_type='b0', input_shape= (224,224,3), n_classes = 322):\r\n",
        "  if version == 'v1':\r\n",
        "    if model_type == 'b0':\r\n",
        "      base_model = efficientnet_v2.EfficientNetV1(model_type, input_shape=input_shape, num_classes=0, include_preprocessing=False,  pretrained='imagenet')\r\n",
        "    elif model_type == 'b1':\r\n",
        "      base_model = efficientnet_v2.EfficientNetV1(model_type, input_shape=input_shape, num_classes=0,include_preprocessing=False, pretrained='imagenet')\r\n",
        "  \r\n",
        "  elif version == 'v2':\r\n",
        "    if model_type == 'b0':\r\n",
        "      base_model = efficientnet_v2.EfficientNetV2(model_type, input_shape=input_shape, num_classes=0, include_preprocessing=False, pretrained='imagenet')\r\n",
        "    elif model_type == 'b1':\r\n",
        "      base_model = efficientnet_v2.EfficientNetV2(model_type, input_shape=input_shape, num_classes=0, include_preprocessing=False, pretrained='imagenet')\r\n",
        "      \r\n",
        "  model = Sequential()\r\n",
        "  model.add(Input(shape=input_shape))\r\n",
        "  model.add(base_model)\r\n",
        "  model.add(GlobalAveragePooling2D())\r\n",
        "  model.add(Dropout(0.2))\r\n",
        "  model.add(Dense(n_classes, activation='softmax'))\r\n",
        "  \r\n",
        "\r\n",
        "  return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "KtzYKmm0hsu-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 콜백함수 정의"
      ],
      "metadata": {
        "id": "i0B4oC6Thsu-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "source": [
        "# callback\r\n",
        "modelname = f'./data/checkpoint-epoch-{epochs}-batch-{batch_size}-trial-005.h5'\r\n",
        "\r\n",
        "checkpoint = ModelCheckpoint(modelname,\r\n",
        "                             monitor='val_loss',\r\n",
        "                             save_best_only=True,\r\n",
        "                             mode='auto'\r\n",
        "                            )\r\n",
        "\r\n",
        "reduceLR = ReduceLROnPlateau(monitor='val_loss',\r\n",
        "                             factor=0.5,\r\n",
        "                             patience=2\r\n",
        "                             )\r\n",
        "\r\n",
        "earlystopping = EarlyStopping(monitor='val_loss',\r\n",
        "                              patience=5,\r\n",
        "                             )"
      ],
      "outputs": [],
      "metadata": {
        "id": "4k0xFwzMhsu-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (선택1-1) Model 생성"
      ],
      "metadata": {
        "id": "SNoUWWbkhsu_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# model = create_model(version = 'v2', model_type='b1', input_shape= input_shape, n_classes = num_classes)\r\n",
        "\r\n",
        "# model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['acc'])\r\n",
        "# model.summary()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u-7ibvkhsu_",
        "outputId": "354eed33-374b-4a7f-b143-a9fe09da3e17"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model 학습"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# history = model.fit(train_generator, \r\n",
        "#                  steps_per_epoch=NUM_TRAIN/batch_size,\r\n",
        "#                  validation_data=validation_generator, \r\n",
        "#                  validation_steps=NUM_TEST/batch_size,\r\n",
        "#                  epochs=epochs,\r\n",
        "#                  callbacks = [checkpoint, earlystopping],\r\n",
        "#                  verbose = 1)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model 학습률 그래프"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "# #Plotting \r\n",
        "# acc = history.history['acc'] \r\n",
        "# val_acc = history.history['val_acc'] \r\n",
        "# loss = history.history['loss'] \r\n",
        "# val_loss = history.history['val_loss'] \r\n",
        "\r\n",
        "# plt.figure(figsize=(8, 8)) \r\n",
        "\r\n",
        "# plt.subplot(2, 1, 1) \r\n",
        "# plt.plot(acc, label='Training Accuracy') \r\n",
        "# plt.plot(val_acc, label='Validation Accuracy') \r\n",
        "# plt.legend(loc='lower right') \r\n",
        "# plt.ylabel('Accuracy') \r\n",
        "# plt.ylim([min(plt.ylim()),1]) \r\n",
        "# plt.title('Training and Validation Accuracy') \r\n",
        "\r\n",
        "# plt.subplot(2, 1, 2) \r\n",
        "# plt.plot(loss, label='Training Loss') \r\n",
        "# plt.plot(val_loss, label='Validation Loss') \r\n",
        "# plt.legend(loc='upper right') \r\n",
        "# plt.ylabel('Cross Entropy') \r\n",
        "# plt.ylim([0,10]) \r\n",
        "# plt.title('Training and Validation Loss') \r\n",
        "# plt.xlabel('epoch') \r\n",
        "# plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Save"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# savemodel = model\r\n",
        "# filepath = './data/v2_b1_model_240x240.h5'\r\n",
        "# keras.models.save_model(model = savemodel, filepath=filepath)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (선택1-2) 학습된 Model 불러오기"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "source": [
        "model_path = './data/[4]input 96600, model B0, inputsize (240,240), freeze 0, batchsize 64, epoch 30.h5'\r\n",
        "model = keras.models.load_model(model_path)\r\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['acc'])\r\n",
        "model.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "EfficientNetV2 (Functional)  (None, 8, 8, 1280)        5919312   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 322)               412482    \n",
            "=================================================================\n",
            "Total params: 6,331,794\n",
            "Trainable params: 6,271,186\n",
            "Non-trainable params: 60,608\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 히트맵"
      ],
      "metadata": {
        "id": "SYtTwgH1-kaA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "source": [
        "def make_gradcam_heatmap(img_array, model, pre_trained,last_conv_layer_name, classifier_layer_names):\r\n",
        "    \r\n",
        "    # First, we create a model that maps the input image to the activations\r\n",
        "    # of the last conv layer\r\n",
        "    last_conv_layer  = model.get_layer(pre_trained).get_layer(last_conv_layer_name)\r\n",
        "    conv_model       = keras.Model(model.get_layer(pre_trained).inputs, last_conv_layer.output)\r\n",
        "    # Second, we create a model that maps the activations of the last conv\r\n",
        "    # layer to the final class predictions\r\n",
        "    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\r\n",
        "    x = classifier_input\r\n",
        "    \r\n",
        "    for layer_name in classifier_layer_names:\r\n",
        "        x = model.get_layer(layer_name)(x)\r\n",
        "\r\n",
        "    classifier_model = keras.Model(classifier_input, x)\r\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\r\n",
        "    # with respect to the activations of the last conv layer  \r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "        # Compute activations of the last conv layer and make the tape watch it\r\n",
        "        last_conv_layer_output = conv_model(img_array)\r\n",
        "        tape.watch(last_conv_layer_output)\r\n",
        "        \r\n",
        "        # Compute class predictions\r\n",
        "        preds = classifier_model(last_conv_layer_output)\r\n",
        "        top_pred_index = tf.argmax(preds[0])\r\n",
        "        top_class_channel = preds[:, top_pred_index]\r\n",
        "\r\n",
        "    # This is the gradient of the top predicted class with regard to\r\n",
        "    # the output feature map of the last conv layer\r\n",
        "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\r\n",
        "    \r\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\r\n",
        "    # over a specific feature map channel\r\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\r\n",
        "\r\n",
        "    # We multiply each channel in the feature map array\r\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\r\n",
        "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\r\n",
        "\r\n",
        "    # is our saliency heatmap of class activation\r\n",
        "    saliency = np.mean(last_conv_layer_output, axis=-1)\r\n",
        "    saliency = np.maximum(saliency, 0) / np.max(saliency)\r\n",
        "\r\n",
        "    # We multiply each channel in the feature map array\r\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\r\n",
        "    pooled_grads = pooled_grads.numpy()\r\n",
        "    \r\n",
        "    for i in range(pooled_grads.shape[-1]):\r\n",
        "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\r\n",
        "\r\n",
        "    # The channel-wise mean of the resulting feature map\r\n",
        "    # is our grad_cam heatmap of class activation\r\n",
        "    grad_cam = np.mean(last_conv_layer_output, axis=-1)\r\n",
        "    grad_cam = np.maximum(grad_cam, 0) / np.max(grad_cam)\r\n",
        "\r\n",
        "    return grad_cam, saliency"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "source": [
        "def merge_with_heatmap(original_img, heatmap):\r\n",
        "    original_img = np.array(original_img)\r\n",
        "    resized_heatmap=resize(heatmap, (240, 240))\r\n",
        "    resized_heatmap = np.uint8(255*resized_heatmap)\r\n",
        "    resized_heatmap = cv2.applyColorMap(resized_heatmap, cv2.COLORMAP_JET)\r\n",
        "    #resized_heatmap = cv2.cvtColor(resized_heatmap, cv2.COLOR_RGB2BGR)\r\n",
        "    return cv2.addWeighted(resized_heatmap, 0.7, original_img, 0.5, 6)\r\n",
        "\r\n",
        "def convert_to_heatmap(heatmap):\r\n",
        "    heatmap = np.uint8(255*heatmap)\r\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\r\n",
        "    return cv2.cvtColor(heatmap, cv2.COLOR_RGB2BGR)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "source": [
        "def show_hotmap (img, heatmap, title='Heatmap', alpha=0.6, cmap='jet', axisOnOff='off'):\r\n",
        "    '''\r\n",
        "    img     :    Image\r\n",
        "    heatmap :    2d narray\r\n",
        "    '''\r\n",
        "    resized_heatmap=resize(heatmap, img.size)\r\n",
        "    \r\n",
        "    fig, ax = plt.subplots()\r\n",
        "    ax.imshow(img)\r\n",
        "    ax.imshow(resized_heatmap, alpha=alpha, cmap=cmap)\r\n",
        "    plt.axis(axisOnOff)\r\n",
        "    plt.title(title)\r\n",
        "    plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 테스트"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "source": [
        "def prepare_single_input(img_path, target_size=(224, 224)):\r\n",
        "    img = image.load_img(img_path, target_size=target_size)\r\n",
        "    img = image.img_to_array(img)\r\n",
        "    img /= 255.\r\n",
        "    img = np.expand_dims(img, axis= 0) # (1, 224, 224, 3)\r\n",
        "    return img"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "source": [
        "def predict_image(Mymodel, img_path, top_k_num = 3):\r\n",
        "    image = prepare_single_input(img_path, target_size = (240, 240))\r\n",
        "    result = Mymodel.predict([image])[0]\r\n",
        "\r\n",
        "    result = list(result)\r\n",
        "    \r\n",
        "    classname_list = []\r\n",
        "    pred_value_list = []\r\n",
        "    for _ in range(top_k_num) :\r\n",
        "      index= result.index(max(result))\r\n",
        "      classname_list.append(classes_dict[index])\r\n",
        "      pred_value_list.append(max(result))\r\n",
        "      result[index] = 0.\r\n",
        "\r\n",
        "    return classname_list, pred_value_list"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "source": [
        "classes_dict = validation_generator.class_indices\r\n",
        "classes_dict = dict(map(reversed, classes_dict.items()))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "source": [
        "model.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "EfficientNetV2 (Functional)  (None, 8, 8, 1280)        5919312   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 322)               412482    \n",
            "=================================================================\n",
            "Total params: 6,331,794\n",
            "Trainable params: 6,271,186\n",
            "Non-trainable params: 60,608\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "source": [
        "######################################################################################\r\n",
        "#defalut classifier_layer_names #기본 classifier_layer입니다.\r\n",
        "#classifier_layer_names =  ['global_average_pooling2d', 'dropout', 'dense']\r\n",
        "classifier_layers =  model.layers[-3:]\r\n",
        "classifier_layer_names = []\r\n",
        "for layer in classifier_layers:\r\n",
        "    classifier_layer_names.append(layer.name)\r\n",
        "last_conv_layer_name   = 'post_swish'\r\n",
        "pre_train= 'EfficientNetV2'\r\n",
        "Top_K = 1\r\n",
        "\r\n",
        "true_cnt = 0\r\n",
        "false_cnt = 0\r\n",
        "\r\n",
        "#####################################################################################\r\n",
        "image_paths = glob.glob('./data/test/dataset/**/*.jpg')\r\n",
        "for path in tqdm(image_paths, total = len(image_paths)) :\r\n",
        "    img = Image.open(path).resize(size=input_shape[:2])  \r\n",
        "    img_array = prepare_single_input(path, input_shape[:2])\r\n",
        "    #test\r\n",
        "    grad_cam, saliency = make_gradcam_heatmap(img_array, model, pre_train,last_conv_layer_name, classifier_layer_names)\r\n",
        "    pred_classnames, pred_values = predict_image(model, path)\r\n",
        "\r\n",
        "\r\n",
        "    grad_cam_merge = merge_with_heatmap(img, grad_cam)\r\n",
        "    saliency_merge = merge_with_heatmap(img, saliency)\r\n",
        "\r\n",
        "    grad_cam = convert_to_heatmap(grad_cam)\r\n",
        "    saliency = convert_to_heatmap(saliency)\r\n",
        "\r\n",
        "    #save\r\n",
        "\r\n",
        "    #./data/test/dataset\\BMW_SUV_X5_2019-2020\\MAH02945_1017.jpg1.jpg -> BMW_SUV_X5_2019-2020\r\n",
        "    true_classname = path.split('\\\\')[1]\r\n",
        "\r\n",
        "    for index, pred_classname in enumerate(pred_classnames) :\r\n",
        "        #BMW/SUV_X5/2019-2020 -> BMW_SUV_X5_2019-2020 True_class와 맞추기 위해서.\r\n",
        "        pred_classnames[index] = pred_classname.replace('/','_')\r\n",
        "\r\n",
        "    #pred_values안에 0.1이 있다면 True 그렇지 않다면 False인 리스트 생성\r\n",
        "    flag_pred_value = list(map(lambda x : True if x >= 0.1 else False, pred_values))\r\n",
        "\r\n",
        "    #실제 클래스와 예측 클래스가 일치하면, 그리고 predict_value가 0.1이상이라면 실행\r\n",
        "    #Select save path True or False\r\n",
        "    if (true_classname in pred_classnames) & (True in flag_pred_value) : \r\n",
        "        true_cnt+=1\r\n",
        "        #./data/test/dataset\\BMW_SUV_X5_2019-2020\\MAH02945_1017.jpg1.jpg -> ./data/test/result/true/MAH02945_1017.jpg1.jpg\r\n",
        "        split_paths = path.split('\\\\')\r\n",
        "        save_path = split_paths[0].replace('dataset','result') +'/' + 'true' + '/' + split_paths[-1]\r\n",
        "    else : \r\n",
        "        false_cnt+=1\r\n",
        "        #./data/test/dataset\\BMW_SUV_X5_2019-2020\\MAH02945_1017.jpg1.jpg -> ./data/test/result/false/MAH02945_1017.jpg1.jpg\r\n",
        "        split_paths = path.split('\\\\')\r\n",
        "        save_path = split_paths[0].replace('dataset','result') +'/' + 'false' + '/' + split_paths[-1]\r\n",
        "\r\n",
        "    #Save original image \r\n",
        "    img.save(save_path)\r\n",
        "    #./data/test_result/true/MAH02945_1017.jpg1.jpg -> ./data/test_result/true or false/MAH02945_1017.jpg1.txt\r\n",
        "    tmp_path = save_path[:-3] + 'txt'\r\n",
        "    with open(tmp_path, \"w\", encoding=\"UTF-8\") as f:\r\n",
        "        f.write(f\"[실제 클래스]\\n\")\r\n",
        "        f.write(f\"{true_classname}\\n\")\r\n",
        "        f.write(f\"[예측 클래스 Top 3]\\n\")\r\n",
        "        f.write(f\"{pred_classnames[0]}, 예측률 : {pred_values[0]}\\n\")\r\n",
        "        f.write(f\"{pred_classnames[1]}, 예측률 : {pred_values[1]}\\n\")\r\n",
        "        f.write(f\"{pred_classnames[2]}, 예측률 : {pred_values[2]}\\n\")\r\n",
        "\r\n",
        "    #Save grad_cam image\r\n",
        "    #./data/test_result/true/MAH02945_1017.jpg1.jpg -> ./data/test_result/true or false/MAH02945_1017.jpg1_gc.jpg\r\n",
        "    tmp_path = save_path[:-4] + '_gc.jpg'\r\n",
        "    plt.figure(figsize=(input_shape[0] / 100, input_shape[0] / 100))\r\n",
        "    plt.imshow(grad_cam)\r\n",
        "    plt.axis('off'), plt.xticks([]), plt.yticks([])\r\n",
        "    plt.tight_layout()\r\n",
        "    plt.subplots_adjust(left = 0, bottom = 0, right = 1, top = 1, hspace = 0, wspace = 0)\r\n",
        "    plt.savefig(tmp_path, bbox_inces='tight', pad_inches=0, dpi=100)\r\n",
        "    plt.close()\r\n",
        "    \r\n",
        "\r\n",
        "    #Save saliency image\r\n",
        "    #./data/test_result/true/MAH02945_1017.jpg1.jpg -> ./data/test_result/true or false/MAH02945_1017.jpg1_sa.jpg\r\n",
        "    tmp_path = save_path[:-4] + '_sa.jpg'\r\n",
        "    plt.figure(figsize=(input_shape[0] / 100, input_shape[0] / 100))\r\n",
        "    plt.imshow(saliency)\r\n",
        "    plt.axis('off'), plt.xticks([]), plt.yticks([])\r\n",
        "    plt.tight_layout()\r\n",
        "    plt.subplots_adjust(left = 0, bottom = 0, right = 1, top = 1, hspace = 0, wspace = 0)\r\n",
        "    plt.savefig(tmp_path, bbox_inces='tight', pad_inches=0, dpi=100)\r\n",
        "    plt.close()\r\n",
        "    \r\n",
        "\r\n",
        "    #Save grad_cam-Merge image\r\n",
        "    #./data/test_result/true/MAH02945_1017.jpg1.jpg -> ./data/test_result/true or false/MAH02945_1017.jpg1_gcm.jpg\r\n",
        "    tmp_path = save_path[:-4] + '_gcm.jpg'\r\n",
        "    cv2.imwrite(tmp_path, grad_cam_merge)\r\n",
        "\r\n",
        "    #Save saliency-Merge image\r\n",
        "    #./data/test_result/true/MAH02945_1017.jpg1.jpg -> ./data/test_result/true or false/MAH02945_1017.jpg1_sam.jpg\r\n",
        "    tmp_path = save_path[:-4] + '_sam.jpg'\r\n",
        "    cv2.imwrite(tmp_path, saliency_merge)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 836/836 [04:04<00:00,  3.42it/s]\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "acc = true_cnt / (true_cnt+false_cnt)\r\n",
        "print(f\"Top{Top_K} Acc : {round(acc,2)}\")"
      ],
      "outputs": [],
      "metadata": {}
    }
  ]
}